{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms as tfs\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from os.path import join\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import os\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debayering(raw):\n",
    "    channel_green_1 = raw[0::2, 1::2]\n",
    "    channel_green_2 = raw[1::2, 0::2]\n",
    "    channel_blue = raw[1::2, 1::2]\n",
    "    channel_red = raw[0::2, 0::2]\n",
    "\n",
    "    image = np.array((channel_red, channel_green_1, channel_green_2, channel_blue))# array instead of dstack\n",
    "    image = image.astype(float) / 255.0 # norm 255 instead of 255 * 4\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetZurich(Dataset):\n",
    "    def __init__(self, dataset_dir, size, istest=False, transform=None):\n",
    "        if istest:\n",
    "            self.raw_dir = join(dataset_dir, 'test', 'huawei_raw')\n",
    "            self.dslr_dir = join(dataset_dir, 'test', 'canon')\n",
    "            \n",
    "        else:\n",
    "            self.raw_dir = join(dataset_dir, 'train', 'huawei_raw')\n",
    "            self.dslr_dir = join(dataset_dir, 'train', 'canon')\n",
    "        \n",
    "        self.dataset_size = size\n",
    "        self.istest = istest\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.dataset_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        raw = imageio.v3.imread(self.raw_dir + '/' + str(idx) + '.png')\n",
    "        raw = np.float32(debayering(raw))\n",
    "        raw = torch.from_numpy(raw) \n",
    "        \n",
    "        dslr = imageio.v3.imread(self.dslr_dir + '/' + str(idx) + '.jpg').astype('uint8')\n",
    "        # dslr = cv2.resize(dslr, (raw.shape[1], raw.shape[2]))\n",
    "        dslr = torch.from_numpy(dslr.transpose((2,0,1))) / 255.0\n",
    "        \n",
    "        if self.transform:\n",
    "            raw, dslr = self.transform(raw, dslr)\n",
    "        return raw, dslr, str(idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetMai(Dataset):\n",
    "    def __init__(self, dataset_dir, size, transform=None):\n",
    "        self.dataset_size = size\n",
    "        self.transform = transform \n",
    "        self.dataset_dir = dataset_dir\n",
    "\n",
    "    def __len__(self):\n",
    "         return self.dataset_size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        raw = imageio.v3.imread(self.dataset_dir + '/mediatek_raw/' + str(index) + '.png')\n",
    "        raw = np.float32(debayering(raw))\n",
    "        raw = torch.from_numpy(raw) \n",
    "        \n",
    "        dslr = imageio.v3.imread(self.dataset_dir + '/fujifilm/' + str(index) + '.png').astype('uint8')\n",
    "        # dslr = cv2.resize(dslr, (raw.shape[1], raw.shape[2]))\n",
    "        dslr = torch.from_numpy(dslr.transpose((2,0,1))) / 255.0\n",
    "        \n",
    "        if self.transform:\n",
    "            raw, dslr = self.transform(raw, dslr)\n",
    "        return raw, dslr, str(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d( 4, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=1)     \n",
    "        self.conv5 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.flat = nn.Flatten() \n",
    "        self.linear1 = nn.Linear(64*64, 512)\n",
    "        self.norm = nn.BatchNorm1d(512)\n",
    "        self.linear2 = nn.Linear(512, 256)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = self.flat(x)\n",
    "        embending = F.relu(self.linear1(x))\n",
    "        embending = self.norm(embending)\n",
    "        embending = F.relu(self.linear2(embending))\n",
    "        embending = nn.functional.normalize(embending, p=2, dim=1)\n",
    "        return x, embending\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.trans1 = nn.ConvTranspose2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.trans2 = nn.ConvTranspose2d(64, 32, kernel_size=3, padding=1, stride=2, output_padding=1)\n",
    "        self.trans3 = nn.ConvTranspose2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.trans4= nn.ConvTranspose2d(32, 16, kernel_size=3, padding=1, stride=2, output_padding=1)\n",
    "        self.trans5 = nn.ConvTranspose2d(16, 16, kernel_size=3, padding=1)\n",
    "        self.trans6 = nn.ConvTranspose2d(16, 4, kernel_size=3, padding=1, stride=2, output_padding=1)\n",
    "\n",
    "    def forward(self, latent_inputs, batch_size):\n",
    "        x = torch.reshape(latent_inputs, (batch_size, 64, 8, 8))\n",
    "        x = F.relu(self.trans1(x))\n",
    "        x = F.relu(self.trans2(x))\n",
    "        x = F.relu(self.trans3(x))\n",
    "        x = F.relu(self.trans4(x))\n",
    "        x = F.relu(self.trans5(x))\n",
    "        decoder_outputs = F.relu(self.trans6(x))\n",
    "        return decoder_outputs\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomCrop(object):\n",
    "    \"\"\" Randomly crops raw and target image reespectively \n",
    "    Args: size(int) shape of new image (size,size) \n",
    "    \"\"\"\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "    \n",
    "    def __call__(self, raw, dslr):\n",
    "        # print(raw.size())\n",
    "        w, h = raw.shape[1:]\n",
    "        i = np.random.randint(0, h - self.size)\n",
    "        j = np.random.randint(0, w - self.size)\n",
    "        cropped_raw = raw[:,i : i + self.size, j : j + self.size]\n",
    "        cropped_dslr = dslr[:,i : i + self.size, j : j + self.size]\n",
    "        return cropped_raw, cropped_dslr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def read_target_image(path: str, size):\n",
    "    image = cv2.imread(path)\n",
    "    if image is None:\n",
    "        raise Exception(f'Can not read image {path}')\n",
    "    image = cv2.resize(image, size)\n",
    "    image = image[:,:,::-1] #bgr -> rgb\n",
    "    return image.astype(np.float32) / 255\n",
    "\n",
    "\n",
    "def read_bayer_image(path: str):\n",
    "    raw = np.asarray(imageio.imread(path))\n",
    "    if raw is None:\n",
    "        raise Exception(f'Can not read image {path}')\n",
    "    ch_B  = raw[1::2, 1::2]\n",
    "    ch_Gb = raw[0::2, 1::2]\n",
    "    ch_R  = raw[0::2, 0::2]\n",
    "    ch_Gr = raw[1::2, 0::2]\n",
    "    combined = np.dstack((ch_B, ch_Gb, ch_R, ch_Gr))\n",
    "    return combined.astype(np.float32) / (4 * 255)\n",
    "\n",
    "\n",
    "def random_crop(image, size):\n",
    "    h, w = image.shape[:2]\n",
    "    x = np.random.randint(0, w - size[0])\n",
    "    y = np.random.randint(0, h - size[1])\n",
    "    return image[y:y+size[1], x:x+size[0]]\n",
    "\n",
    "def plt_display(image, title):\n",
    "    fig = plt.figure()\n",
    "    a = fig.add_subplot(1, 1, 1)\n",
    "    imgplot = plt.imshow(image)\n",
    "    a.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (64, 64)\n",
    "BATCH_SIZE = 64\n",
    "zurich_base_dir = \"/alpha/gosha20777/Zurich-RAW-to-DSLR-Dataset\"\n",
    "mai_base_dir = \"/alpha/gosha20777/MAI2021\"\n",
    "zurich_train_dataset = DatasetZurich(zurich_base_dir, 46839, istest=False, transform=RandomCrop(64))\n",
    "zurich_test_dataset = DatasetZurich(zurich_base_dir, 1204, istest=True, transform=RandomCrop(64))\n",
    "mai_dataser = DatasetMai(mai_base_dir, 24161, transform=RandomCrop(64))\n",
    "mai_train_dataset, mai_test_dataset =  torch.utils.data.random_split(mai_dataser, \n",
    "                                                            [24161-1204, 1204])\n",
    "train_zurich_loader = DataLoader(zurich_train_dataset, \n",
    "                                 BATCH_SIZE, \n",
    "                                 shuffle=True,\n",
    "                                 drop_last=True,\n",
    "                                 pin_memory=True,)\n",
    "train_mai_loader = DataLoader(mai_train_dataset, \n",
    "                                 BATCH_SIZE, \n",
    "                                 shuffle=False,\n",
    "                                 drop_last=True,\n",
    "                                 pin_memory=True)\n",
    "\n",
    "test_mai_loader = DataLoader(mai_test_dataset, \n",
    "                                 BATCH_SIZE, \n",
    "                                 shuffle=False,\n",
    "                                 drop_last=True,\n",
    "                                 pin_memory=True)\n",
    "test_zurich_loader = DataLoader(zurich_test_dataset,\n",
    "                                 BATCH_SIZE, \n",
    "                                 shuffle=False,\n",
    "                                 drop_last=True,\n",
    "                                 pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp\n",
    "def gaussian(window_size, sigma):\n",
    "    gauss = torch.Tensor([exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n",
    "    return gauss/gauss.sum()\n",
    "\n",
    "\n",
    "def create_window(window_size, channel=1):\n",
    "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
    "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "    window = _2D_window.expand(channel, 1, window_size, window_size).contiguous()\n",
    "    return window\n",
    "\n",
    "\n",
    "def ssim(img1, img2, window_size=11, window=None, size_average=True, full=False, val_range=None):\n",
    "    # Value range can be different from 255. Other common ranges are 1 (sigmoid) and 2 (tanh).\n",
    "    if val_range is None:\n",
    "        if torch.max(img1) > 128:\n",
    "            max_val = 255\n",
    "        else:\n",
    "            max_val = 1\n",
    "\n",
    "        if torch.min(img1) < -0.5:\n",
    "            min_val = -1\n",
    "        else:\n",
    "            min_val = 0\n",
    "        L = max_val - min_val\n",
    "    else:\n",
    "        L = val_range\n",
    "\n",
    "    padd = 0\n",
    "    (_, channel, height, width) = img1.size()\n",
    "    if window is None:\n",
    "        real_size = min(window_size, height, width)\n",
    "        window = create_window(real_size, channel=channel).to(img1.device)\n",
    "\n",
    "    mu1 = F.conv2d(img1, window, padding=padd, groups=channel)\n",
    "    mu2 = F.conv2d(img2, window, padding=padd, groups=channel)\n",
    "\n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1 * mu2\n",
    "\n",
    "    sigma1_sq = F.conv2d(img1 * img1, window, padding=padd, groups=channel) - mu1_sq\n",
    "    sigma2_sq = F.conv2d(img2 * img2, window, padding=padd, groups=channel) - mu2_sq\n",
    "    sigma12 = F.conv2d(img1 * img2, window, padding=padd, groups=channel) - mu1_mu2\n",
    "\n",
    "    C1 = (0.01 * L) ** 2\n",
    "    C2 = (0.03 * L) ** 2\n",
    "\n",
    "    v1 = 2.0 * sigma12 + C2\n",
    "    v2 = sigma1_sq + sigma2_sq + C2\n",
    "    cs = torch.mean(v1 / v2)  # contrast sensitivity\n",
    "\n",
    "    ssim_map = ((2 * mu1_mu2 + C1) * v1) / ((mu1_sq + mu2_sq + C1) * v2)\n",
    "\n",
    "    if size_average:\n",
    "        ret = ssim_map.mean()\n",
    "    else:\n",
    "        ret = ssim_map.mean(1).mean(1).mean(1)\n",
    "\n",
    "    if full:\n",
    "        return ret, cs\n",
    "    return ret\n",
    "\n",
    "\n",
    "def msssim(img1, img2, window_size=11, size_average=True, val_range=None, normalize=False):\n",
    "    device = img1.device\n",
    "    weights = torch.FloatTensor([0.0448, 0.2856, 0.3001, 0.2363, 0.1333]).to(device)\n",
    "    levels = weights.size()[0]\n",
    "    mssim = []\n",
    "    mcs = []\n",
    "    for _ in range(levels):\n",
    "        sim, cs = ssim(img1, img2, window_size=window_size, size_average=size_average, full=True, val_range=val_range)\n",
    "        mssim.append(sim)\n",
    "        mcs.append(cs)\n",
    "\n",
    "        img1 = F.avg_pool2d(img1, (2, 2))\n",
    "        img2 = F.avg_pool2d(img2, (2, 2))\n",
    "\n",
    "    mssim = torch.stack(mssim)\n",
    "    mcs = torch.stack(mcs)\n",
    "\n",
    "    # Normalize (to avoid NaNs during training unstable models, not compliant with original definition)\n",
    "    if normalize:\n",
    "        mssim = (mssim + 1) / 2\n",
    "        mcs = (mcs + 1) / 2\n",
    "\n",
    "    pow1 = mcs ** weights\n",
    "    pow2 = mssim ** weights\n",
    "    # From Matlab implementation https://ece.uwaterloo.ca/~z70wang/research/iwssim/\n",
    "    output = torch.prod(pow1[:-1] * pow2[-1])\n",
    "    return output\n",
    "\n",
    "\n",
    "# Classes to re-use window\n",
    "class SSIM(torch.nn.Module):\n",
    "    def __init__(self, window_size=11, size_average=True, val_range=None):\n",
    "        super(SSIM, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.size_average = size_average\n",
    "        self.val_range = val_range\n",
    "\n",
    "        # Assume 1 channel for SSIM\n",
    "        self.channel = 1\n",
    "        self.window = create_window(window_size)\n",
    "\n",
    "    def forward(self, img1, img2):\n",
    "        (_, channel, _, _) = img1.size()\n",
    "\n",
    "        if channel == self.channel and self.window.dtype == img1.dtype:\n",
    "            window = self.window\n",
    "        else:\n",
    "            window = create_window(self.window_size, channel).to(img1.device).type(img1.dtype)\n",
    "            self.window = window\n",
    "            self.channel = channel\n",
    "\n",
    "        return ssim(img1, img2, window=window, window_size=self.window_size, size_average=self.size_average)\n",
    "\n",
    "class MSSSIM(torch.nn.Module):\n",
    "    def __init__(self, window_size=11, size_average=True, channel=3):\n",
    "        super(MSSSIM, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.size_average = size_average\n",
    "        self.channel = channel\n",
    "\n",
    "    def forward(self, img1, img2):\n",
    "        # TODO: store window between calls if possible\n",
    "        return msssim(img1, img2, window_size=self.window_size, size_average=self.size_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mssim(y_true, y_pred):\n",
    "    return 1.0 - ssim(y_pred, y_true)\n",
    "\n",
    "mae_loss = torch.nn.L1Loss(reduction='mean')\n",
    "\n",
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "    log2pi = torch.log(torch.tensor(2. * np.pi))\n",
    "    return torch.sum(\n",
    "          -.5 * ((sample - mean) ** 2. * torch.exp(-logvar) + logvar + log2pi),\n",
    "          dim=raxis)\n",
    "\n",
    "def embedding_loss(y_pred):\n",
    "    # print(y_pred.shape)\n",
    "    mean, logvar = torch.split(y_pred, split_size_or_sections=128, dim=1)\n",
    "    eps = torch.randn(BATCH_SIZE, mean.shape[1]).to(device=device)\n",
    "    z = eps * torch.exp(logvar * .5) + mean\n",
    "    logpz = log_normal_pdf(z, torch.zeros_like(mean), torch.zeros_like(logvar))\n",
    "    logqz_x = log_normal_pdf(z, mean, logvar)\n",
    "    return -torch.mean(logpz - logqz_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_zurich = Encoder().to(device=device)\n",
    "encoder_mai = Encoder().to(device=device)\n",
    "decoder_zurich = Decoder().to(device=device)\n",
    "decoder_mai = Decoder().to(device=device)\n",
    "\n",
    "\n",
    "# params = list(encoder_mai.parameters()) + list(encoder_zurich.parameters()) + list(decoder_mai.parameters()) + list(decoder_zurich.parameters())\n",
    "# optimizer = torch.optim.Adam(params(), lr=10**-3, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "params = chain(encoder_zurich.parameters(), decoder_zurich.parameters())\n",
    "optimizer_zurich = torch.optim.Adam(params, lr=10**-3, betas=(0.9, 0.999))\n",
    "params = chain(encoder_mai.parameters(),decoder_mai.parameters())\n",
    "optimizer_mai = torch.optim.Adam(params, lr=10**-3, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:rs9bwog6) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃▃▃▆▆▆▆▆▆▆▆▆▆▆▆▆█</td></tr><tr><td>train/loss</td><td>▅▂▆▅▄▆▄▄▇▄▅▅▄▅▃▄▇▃▂▄▅▄▄▅▂▄▂█▅▂▃▄▄▁▅▂▄▅▃▄</td></tr><tr><td>val/epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅█████████████</td></tr><tr><td>val/i</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val/loss</td><td>▃▅▃▄▄▅▅▄▃▃▃▄█▂▆▂▅█▇▆▄▃▆▄▅▆▂▇▃▁▄▇▄▅▄▂▄▃▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>3</td></tr><tr><td>train/loss</td><td>0.52254</td></tr><tr><td>val/epoch</td><td>2</td></tr><tr><td>val/i</td><td>54</td></tr><tr><td>val/loss</td><td>0.47018</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">true-firebrand-42</strong> at: <a href='https://wandb.ai/bombandirlol/2%20unet/runs/rs9bwog6' target=\"_blank\">https://wandb.ai/bombandirlol/2%20unet/runs/rs9bwog6</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230328_124805-rs9bwog6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:rs9bwog6). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/panshin/unsupervised_isp/wandb/run-20230328_130900-mpcv2fvv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bombandirlol/2%20unet/runs/mpcv2fvv' target=\"_blank\">zany-monkey-43</a></strong> to <a href='https://wandb.ai/bombandirlol/2%20unet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bombandirlol/2%20unet' target=\"_blank\">https://wandb.ai/bombandirlol/2%20unet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bombandirlol/2%20unet/runs/mpcv2fvv' target=\"_blank\">https://wandb.ai/bombandirlol/2%20unet/runs/mpcv2fvv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/bombandirlol/2%20unet/runs/mpcv2fvv?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f806f25a950>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "        project=\"2 unet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import to_psnr, to_ssim_skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "i= 0\n",
    "\n",
    "for epoch in range(20):\n",
    "    encoder_mai.train()\n",
    "    encoder_zurich.train()\n",
    "    decoder_mai.train()\n",
    "    decoder_zurich.train()\n",
    "    for data_zurich, data_mai in zip(train_zurich_loader, cycle(train_mai_loader)):\n",
    "        x_zurich, target_zurich, _ = data_zurich\n",
    "        x_mai, target_mai, _ = data_mai\n",
    "        x_mai = x_mai.to(device=device)\n",
    "        x_zurich = x_zurich.to(device=device)\n",
    "        target_mai = target_mai.to(device=device)\n",
    "        target_zurich = target_zurich.to(device=device)\n",
    "        # print(x_zurich.shape, x_mai.shape)\n",
    "        latent_layer_zurich, embedding_zurich = encoder_zurich(x_zurich)\n",
    "        latent_layer_mai, embedding_mai =  encoder_mai(x_mai)\n",
    "        out_zurich = decoder_zurich(latent_layer_zurich, BATCH_SIZE)\n",
    "        out_mai = decoder_mai(latent_layer_mai, BATCH_SIZE)\n",
    "\n",
    "        optimizer_mai.zero_grad()\n",
    "        optimizer_zurich.zero_grad()\n",
    "        loss_zurich = embedding_loss(embedding_zurich) + mssim(out_zurich, x_zurich) \n",
    "        loss_zurich += mae_loss(embedding_mai, embedding_zurich)\n",
    "        loss_zurich.backward()\n",
    "        optimizer_zurich.step()\n",
    "        loss_mai = embedding_loss(embedding_mai) + mssim(out_mai, x_mai) \n",
    "        loss_mai += mae_loss(embedding_mai, embedding_zurich)\n",
    "        loss_mai.backward()\n",
    "        optimizer_mai.step()\n",
    "        \n",
    "        metrics = {\n",
    "            'train/loss': loss,\n",
    "            # 'train/ssim_mai': to_ssim_skimage(out_mai, x_mai),\n",
    "            # 'train/ssim_zuroich': to_ssim_skimage(out_zurich, x_zurich),\n",
    "            # 'train/psnr_mai': to_psnr(out_mai, x_mai),\n",
    "            # 'train/psnr_zurich': to_psnr(out_zurich, x_zurich),\n",
    "            'train/epoch': epoch\n",
    "        }\n",
    "        wandb.log(metrics)\n",
    "        scheduler.step(loss_mai+loss_zurich)\n",
    "\n",
    "    encoder_mai.eval()\n",
    "    encoder_zurich.eval()\n",
    "    decoder_mai.eval()\n",
    "    decoder_zurich.eval()\n",
    "\n",
    "    for data_zurich, data_mai in zip(test_zurich_loader, cycle(test_mai_loader)):\n",
    "        with torch.no_grad():\n",
    "            x_zurich, target_zurich, _ = data_zurich\n",
    "            x_mai, target_mai, _ = data_mai\n",
    "            x_mai = x_mai.to(device=device)\n",
    "            x_zurich = x_zurich.to(device=device)\n",
    "            target_mai = target_mai.to(device=device)\n",
    "            target_zurich = target_zurich.to(device=device)\n",
    "            \n",
    "            latent_layer_zurich, embedding_zurich = encoder_zurich(x_zurich)\n",
    "            latent_layer_mai, embedding_mai =  encoder_mai(x_mai)\n",
    "            out_zurich = decoder_zurich(latent_layer_zurich, BATCH_SIZE)\n",
    "            out_mai = decoder_mai(latent_layer_mai, BATCH_SIZE)\n",
    "            \n",
    "            i += 1\n",
    "            \n",
    "            metrics = {\n",
    "                'val/i': i,\n",
    "                'val/mae': mae_loss(embedding_mai, embedding_zurich),\n",
    "                'val/ssim_mai': to_ssim_skimage(out_mai, x_mai)[0],\n",
    "                'val/ssim_zuroich': to_ssim_skimage(out_zurich, x_zurich)[0],\n",
    "                'val/psnr_mai': to_psnr(out_mai, x_mai)[0],\n",
    "                'val/psnr_zurich': to_psnr(out_zurich, x_zurich)[0],\n",
    "                'val/epoch': epoch\n",
    "            }\n",
    "            wandb.log(metrics)        \n",
    "\n",
    "        \n",
    "wandb.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[39m.\u001b[39msave(encoder_mai\u001b[39m.\u001b[39mstate_dict(), \u001b[39m'\u001b[39m\u001b[39m./mai_encoder.pkl\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m torch\u001b[39m.\u001b[39msave(encoder_zurich\u001b[39m.\u001b[39mstate_dict(),\u001b[39m'\u001b[39m\u001b[39m./zurich_encoder.pkl\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m torch\u001b[39m.\u001b[39msave(decoder_mai\u001b[39m.\u001b[39mstate_dict(), \u001b[39m'\u001b[39m\u001b[39m./mai_decoder.pkl\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "torch.save(encoder_mai.state_dict(), './mai_encoder.pkl')\n",
    "torch.save(encoder_zurich.state_dict(),'./zurich_encoder.pkl')\n",
    "torch.save(decoder_mai.state_dict(), './mai_decoder.pkl')\n",
    "torch.save(decoder_zurich.state_dict(),'./zurich_decoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "212992/8/8/64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vaevenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eb5a62bdf42607cce6b64131384fd950931b7966e25ae4bca7b3e40565a561d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
